{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAR_UCI-HAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWUtP_QQmiwC"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0mWgcF4mmZh"
      },
      "source": [
        "This notebook presents the several machine learning models using CNN and LSTM for HAR. To obtain a detailed description of the architecture, please refer to the dissertation, **\"RECOGNISING HUMAN ACTIVITIES AUTONOMOUSLY THROUGH FUSION OF SENSOR DATA\"**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR7qSIb2mrzQ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeGCJmMKBOVV"
      },
      "source": [
        "As a dataset, the [Human Activity Recognition Using Smartphones Data Set](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) is used. To prepare this dataset for the program, the following code is uncommented and executed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kYwL00dBZ_K"
      },
      "source": [
        "# Download dataset zip file and place data files in training and test set directries\n",
        "\n",
        "zipfile_dataset_uci_har = \"UCI HAR Dataset.zip\"\n",
        "url_dataset_uci_har = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\"\n",
        "\n",
        "#!wget $url_dataset_uci_har\n",
        "#!unzip \"$zipfile_dataset_uci_har\"\n",
        "#!ls \"UCI HAR Dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmCYvllE_gnC"
      },
      "source": [
        "# 1.Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kp6JJcVm7MR"
      },
      "source": [
        "Adjustable flags and parameters are listed. Hyperparameters for each ML model are in \"[F] ML models\" section.\n",
        "\n",
        "|Name|Type|Explanation|\n",
        "|-|-|-|\n",
        "|flag_(ML model name)|Flag|Whether execute the model or not|\n",
        "|flag_experiment|Flag|Whether run repeated evaluation for summary statistics or not|\n",
        "|flag_model_load|Flag|Whether load the model from the file or not|\n",
        "|flag_model_save|Flag|Whether save the model to the file after training or not|\n",
        "|flag_EarlyStopping|Flag|Enable Early stopping|\n",
        "|flag_es_monitor|Flag|Monitor type for Early stopping|\n",
        "|ratio_train|Parameter|The ratio between training and validation sets|\n",
        "|seed|Parameter|Fix the seed for reproducibility|\n",
        "|flag_scale|Flag|Scaling technique|\n",
        "|flag_data_dist|Flag|Display dataset distribution|\n",
        "|flag_plot_model|Flag|Whether plot model graphs or not|\n",
        "|flag_save_fig|Flag|Whether save graphs or not|\n",
        "|flag_summary|Flag|Show summary of the dataset|\n",
        "|flag_cm_norm|Flag|Whether normalise confusion matrix or not|\n",
        "|flag_TensorBoard|Flag|Whether save the Tensorboard data or not|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGmRyjGiCqFE"
      },
      "source": [
        "### [Note]\n",
        "#\n",
        "# Hyperparameters for each ML model are in \"[F] ML models\" section\n",
        "#\n",
        "### ---------- ---------- ---------- ---------- ----------\n",
        "### Flags\n",
        "\n",
        "# ML\n",
        "flag_CNN_1d         = True\n",
        "flag_LSTM_Mto1      = True\n",
        "flag_CNN1D_LSTM     = True\n",
        "flag_ConvLSTM       = True\n",
        "flag_Ensemble       = True\n",
        "\n",
        "flag_experiment     = True\n",
        "\n",
        "flag_model_load     = False\n",
        "flag_model_save     = True\n",
        "\n",
        "flag_EarlyStopping  = True\n",
        "flag_es_monitor     = \"val_loss\"\n",
        "#flag_es_monitor     = \"val_accuracy\"\n",
        "### ---------- ---------- ---------- ---------- ----------\n",
        "### Pre-processing\n",
        "# Ratio of training dataset to be split\n",
        "ratio_train = 0.85\n",
        "\n",
        "# Randam seed for reproducibility\n",
        "seed = 7\n",
        "\n",
        "# scaling\n",
        "flag_scaling        = \"Std\" # for Gaussian\n",
        "#flag_scaling        = \"Norm\" # (0 - 1)\n",
        "### ---------- ---------- ---------- ---------- ----------\n",
        "### Evaluation\n",
        "flag_data_dist      = False\n",
        "flag_plot_model     = True\n",
        "flag_savefig        = True\n",
        "\n",
        "flag_summary        = True\n",
        "flag_cm_norm        = True\n",
        "\n",
        "flag_TensorBoard    = False\n",
        "### ---------- ---------- ---------- ---------- ----------\n",
        "### Directories\n",
        "dir_log = 'log'\n",
        "dir_model = 'model'\n",
        "### ---------- ---------- ---------- ---------- ----------\n",
        "### Names\n",
        "# models\n",
        "modelname_cnn_1d         = 'CNN_1D'\n",
        "modelname_lstm_Mto1      = 'LSTM_Mto1'\n",
        "modelname_lstm_MtoM      = 'LSTM_MtoM'\n",
        "modelname_cnn1d_lstm     = 'CNN1D_LSTM'\n",
        "modelname_convlstm       = 'ConvLSTM'\n",
        "modelname_ensemble       = 'Ensemble'\n",
        "modelname_lstm_Mto1_null = 'LSTM_Mto1_null'\n",
        "\n",
        "# Label list\n",
        "labels_activity = ['WALKING',\n",
        "                   'UPSTAIRS',\n",
        "                   'DOWNSTAIRS',\n",
        "                   'SITTING',\n",
        "                   'STANDING',\n",
        "                   'LAYING']\n",
        "### ---------- ---------- ---------- ---------- ----------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EysX8aadPofF"
      },
      "source": [
        "# 2.Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z2SyAlvgjaF"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axdkz_2aIA2t"
      },
      "source": [
        "# Pre-process\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import pandas as pd\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from datetime import datetime\n",
        "from numpy import mean, std\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "# NNs\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "# CNN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Input, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# LSTM\n",
        "from tensorflow.keras.layers import LSTM, TimeDistributed\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# ConvLSTM\n",
        "from tensorflow.keras.layers import ConvLSTM2D\n",
        "\n",
        "# Ensemble\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdVQya14Q3t1"
      },
      "source": [
        "# Set random seed (for reproducibility)\n",
        "# Hash seed\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "# Built-in random\n",
        "rn.seed(seed)\n",
        "\n",
        "# Numpy.random\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Tensorflow\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfwP11LziJOI"
      },
      "source": [
        "## [F] Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urCdwgEniO-z"
      },
      "source": [
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\n",
        "\treturn loaded\n",
        " \n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\n",
        "\treturn X, y\n",
        " \n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'UCI HAR Dataset/')\n",
        "\tprint(f'Train: {trainX.shape} {trainy.shape}')\n",
        "\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_group('test', prefix + 'UCI HAR Dataset/')\n",
        "\tprint(f'Test: {testX.shape} {testy.shape}')\n",
        "\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\n",
        "\treturn trainX, trainy, testX, testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG3wuJis34qR"
      },
      "source": [
        "## [F] ML models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoCODptk4qxw"
      },
      "source": [
        "# Train\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "repeats = 10\n",
        "\n",
        "# EarlyStopping\n",
        "es_patience = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOKqgOtTKMY4"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBwsKgbW6kxj"
      },
      "source": [
        "# Layer\n",
        "cnn_padding ='same'\n",
        "cnn_activation = 'relu'\n",
        "cnn_units = 128\n",
        "cnn_dropout = 0.5\n",
        "cnn_pool_size = 2\n",
        "cnn_weight_decay = 1e-4\n",
        "\n",
        "## 1D Conv\n",
        "cnn_1d_filters = 64\n",
        "cnn_1d_kernel_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2sM5-KLIugQ"
      },
      "source": [
        "def build_model_cnn_1d():\n",
        "    model = Sequential(name=modelname_cnn_1d)\n",
        "\n",
        "    # Conv layer 1\n",
        "    model.add(Conv1D(\n",
        "        input_shape = cnn_1d_input_shape,\n",
        "        filters     = cnn_1d_filters,\n",
        "        kernel_size = cnn_1d_kernel_size,\n",
        "        padding     = cnn_padding,\n",
        "        activation  = cnn_activation))\n",
        "\n",
        "    # Conv layer 2\n",
        "    model.add(Conv1D(\n",
        "        filters     = cnn_1d_filters,\n",
        "        kernel_size = cnn_1d_kernel_size,\n",
        "        padding     = cnn_padding,\n",
        "        activation  = cnn_activation))\n",
        "\n",
        "    # Conv layer 3\n",
        "    model.add(Conv1D(\n",
        "        filters     = cnn_1d_filters,\n",
        "        kernel_size = cnn_1d_kernel_size,\n",
        "        padding     = cnn_padding,\n",
        "        activation  = cnn_activation))\n",
        "\n",
        "    # Conv layer 4\n",
        "    model.add(Conv1D(\n",
        "        filters     = cnn_1d_filters,\n",
        "        kernel_size = cnn_1d_kernel_size,\n",
        "        padding     = cnn_padding,\n",
        "        activation  = cnn_activation))\n",
        "\n",
        "    # Maxpool layer\n",
        "    # model.add(MaxPool1D(\n",
        "    #     pool_size = cnn_pool_size))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Dense layer 1\n",
        "    model.add(Dense(\n",
        "        units      = cnn_units,\n",
        "        activation = 'relu'))\n",
        "\n",
        "    # Dropout\n",
        "    model.add(Dropout(cnn_dropout))\n",
        "\n",
        "    # Dense layer 2\n",
        "    model.add(Dense(\n",
        "        units      = cnn_units,\n",
        "        activation = 'relu'))\n",
        "\n",
        "    # Dropout\n",
        "    model.add(Dropout(cnn_dropout))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(\n",
        "        units      = num_classes,\n",
        "        activation = 'softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss       = 'categorical_crossentropy',\n",
        "        optimizer  = 'adam',\n",
        "        metrics    = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1xpyw17xvCP"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21V53fOV6oAe"
      },
      "source": [
        "# Layer\n",
        "lstm_units = 128\n",
        "lstm_dropout = 0.5\n",
        "lstm_weight_decay = 1e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXNIOAt-IeaQ"
      },
      "source": [
        "# LSTM (Many-to-One, stateless)\n",
        "def build_model_lstm_Mto1():\n",
        "    model = Sequential(name=modelname_lstm_Mto1)\n",
        "\n",
        "    # LSTM layer\n",
        "    model.add(LSTM(\n",
        "        input_shape        = lstm_input_shape,\n",
        "        units              = lstm_units,\n",
        "        # kernel_regularizer = regularizers.l2(lstm_weight_decay),\n",
        "        return_sequences   = False)) # final layer of LSTM (only final output)\n",
        "\n",
        "    # Dropout\n",
        "    model.add(Dropout(lstm_dropout))\n",
        "\n",
        "    # Dense layer\n",
        "    model.add(Dense(\n",
        "        units      = lstm_units,\n",
        "        activation = 'relu'))\n",
        "\n",
        "    # Dropout\n",
        "    #model.add(Dropout(lstm_dropout))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(\n",
        "        units      = num_classes,\n",
        "        activation = 'softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss       = 'categorical_crossentropy',\n",
        "        optimizer  = 'adam',\n",
        "        metrics    = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zncSMHCRDJd"
      },
      "source": [
        "### CNN-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvEUT7LSE3SV"
      },
      "source": [
        "# Data\n",
        "cnn_lstm_steps = 4\n",
        "\n",
        "# Layer\n",
        "cnn_lstm_padding = 'same'\n",
        "cnn_lstm_activation = 'relu'\n",
        "cnn_lstm_dropout = 0.5\n",
        "cnn_lstm_pool_size = 2\n",
        "\n",
        "## CNN\n",
        "cnn_lstm_filters = 64\n",
        "cnn1d_lstm_kernel_size = 3\n",
        "\n",
        "# LSTM\n",
        "cnn_lstm_units = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgdO9LzIRCg2"
      },
      "source": [
        "def build_model_cnn1d_lstm():\n",
        "    model = Sequential(name=modelname_cnn1d_lstm)\n",
        "\n",
        "    ## CNN (with TimeDistributed)\n",
        "    # Conv layer 1\n",
        "    model.add(TimeDistributed(Conv1D(\n",
        "        filters     = cnn_lstm_filters,\n",
        "        kernel_size = cnn1d_lstm_kernel_size,\n",
        "        padding     = cnn_lstm_padding,\n",
        "        activation  = cnn_lstm_activation),\n",
        "        input_shape = cnn1d_lstm_input_shape))\n",
        "\n",
        "    # Conv layer 2\n",
        "    model.add(TimeDistributed(Conv1D(\n",
        "        filters     = cnn_lstm_filters,\n",
        "        kernel_size = cnn1d_lstm_kernel_size,\n",
        "        padding     = cnn_lstm_padding,\n",
        "        activation  = cnn_lstm_activation)))\n",
        "\n",
        "    # Conv layer 3\n",
        "    model.add(TimeDistributed(Conv1D(\n",
        "        filters     = cnn_lstm_filters,\n",
        "        kernel_size = cnn1d_lstm_kernel_size,\n",
        "        padding     = cnn_lstm_padding,\n",
        "        activation  = cnn_lstm_activation)))\n",
        "\n",
        "    # Conv layer 4\n",
        "    model.add(TimeDistributed(Conv1D(\n",
        "        filters     = cnn_lstm_filters,\n",
        "        kernel_size = cnn1d_lstm_kernel_size,\n",
        "        padding     = cnn_lstm_padding,\n",
        "        activation  = cnn_lstm_activation)))\n",
        "\n",
        "    # Dropout\n",
        "    model.add(TimeDistributed(Dropout(cnn_lstm_dropout)))\n",
        "\n",
        "    # Maxpool layer\n",
        "    model.add(TimeDistributed(MaxPool1D(\n",
        "        pool_size = cnn_lstm_pool_size)))\n",
        "\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "    ## LSTM\n",
        "    # LSTM layer 1\n",
        "    model.add(LSTM(\n",
        "        units            = cnn_lstm_units,\n",
        "        return_sequences = True))\n",
        "\n",
        "    # Dropout\n",
        "    model.add(Dropout(cnn_lstm_dropout))\n",
        "\n",
        "    # LSTM layer 2\n",
        "    model.add(LSTM(\n",
        "        units            = cnn_lstm_units,\n",
        "        return_sequences = False))\n",
        "\n",
        "    # Dropout\n",
        "    model.add(Dropout(cnn_lstm_dropout))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(\n",
        "        units      = num_classes,\n",
        "        activation = 'softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss       = 'categorical_crossentropy',\n",
        "        optimizer  = 'adam',\n",
        "        metrics    = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLfIZcB0TVvV"
      },
      "source": [
        "### ConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DZU2MiDTYJn"
      },
      "source": [
        "# Data\n",
        "convlstm_steps = 4\n",
        "\n",
        "# Layer\n",
        "convlstm_padding = 'same'\n",
        "convlstm_activation = 'relu'\n",
        "convlstm_dropout = 0.5\n",
        "convlstm_pool_size = 2\n",
        "\n",
        "## CNN\n",
        "convlstm_filters = 64\n",
        "convlstm_kernel_size = (1, 3)\n",
        "\n",
        "convlstm_units = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3v-Tb39UxOE"
      },
      "source": [
        "def build_model_convlstm():\n",
        "    model = Sequential(name=modelname_convlstm)\n",
        "\n",
        "    # Conv LSTM layer 1\n",
        "    model.add(ConvLSTM2D(\n",
        "        filters          = convlstm_filters,\n",
        "        kernel_size      = convlstm_kernel_size,\n",
        "        padding          = convlstm_padding,\n",
        "        activation       = convlstm_activation,\n",
        "        input_shape      = convlstm_input_shape,\n",
        "        return_sequences = True))\n",
        "        # return_sequences = False)) # final layer of LSTM (only final output)\n",
        "\n",
        "    # Conv LSTM layer 2\n",
        "    model.add(ConvLSTM2D(\n",
        "        filters          = convlstm_filters,\n",
        "        kernel_size      = convlstm_kernel_size,\n",
        "        padding          = convlstm_padding,\n",
        "        activation       = convlstm_activation,\n",
        "        return_sequences = True))\n",
        "\n",
        "    # Conv LSTM layer 3\n",
        "    model.add(ConvLSTM2D(\n",
        "        filters          = convlstm_filters,\n",
        "        kernel_size      = convlstm_kernel_size,\n",
        "        padding          = convlstm_padding,\n",
        "        activation       = convlstm_activation,\n",
        "        return_sequences = True))\n",
        "\n",
        "    # Conv LSTM layer 4\n",
        "    model.add(ConvLSTM2D(\n",
        "        filters          = convlstm_filters,\n",
        "        kernel_size      = convlstm_kernel_size,\n",
        "        padding          = convlstm_padding,\n",
        "        activation       = convlstm_activation,\n",
        "        return_sequences = False))\n",
        "\n",
        "    # Dropout\n",
        "    model.add(Dropout(convlstm_dropout))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Dense layer\n",
        "    model.add(Dense(\n",
        "        units      = convlstm_units,\n",
        "        activation = convlstm_activation))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(\n",
        "        units      = num_classes,\n",
        "        activation = 'softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss       = 'categorical_crossentropy',\n",
        "        optimizer  = 'adam',\n",
        "        metrics    = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE3gj-xPDTC5"
      },
      "source": [
        "### Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXjgB_0wDf_x"
      },
      "source": [
        "# Layer\n",
        "ensemble_units = 10\n",
        "ensemble_activation = 'relu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfxC8c1RDRo6"
      },
      "source": [
        "def build_model_ensemble(inputs, outputs):\n",
        "    ensemble_merge = Concatenate(axis=1)(outputs)\n",
        "\n",
        "    # Dense layer\n",
        "    ensemble_hidden = Dense(\n",
        "        units      = ensemble_units,\n",
        "        activation = ensemble_activation)(ensemble_merge)\n",
        "\n",
        "    # Output layer\n",
        "    ensemble_output = Dense(\n",
        "        units      = num_classes,\n",
        "        activation = 'softmax')(ensemble_hidden)\n",
        "\n",
        "    model = Model(\n",
        "        inputs     = inputs,\n",
        "        outputs    = ensemble_output,\n",
        "        name       = modelname_ensemble)\n",
        "\n",
        "    model.compile(\n",
        "        loss       = 'categorical_crossentropy',\n",
        "        optimizer  = 'adam',\n",
        "        metrics    = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vRs98_f_qhj"
      },
      "source": [
        "## [F] Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjY63c0_hf5H"
      },
      "source": [
        "# Train and evaluate a model (once)\n",
        "def evaluate_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    # Build model\n",
        "    if model_name == modelname_cnn_1d:\n",
        "        model = build_model_cnn_1d()\n",
        "    elif model_name == modelname_lstm_Mto1:\n",
        "        model = build_model_lstm_Mto1()\n",
        "    elif model_name == modelname_lstm_MtoM:\n",
        "        model = build_model_lstm_MtoM()\n",
        "    elif model_name == modelname_cnn1d_lstm:\n",
        "        model = build_model_cnn1d_lstm()\n",
        "    elif model_name == modelname_convlstm:\n",
        "        model = build_model_convlstm()\n",
        "    else:\n",
        "        print(\"Error: specify correct model name\")\n",
        "        return -1\n",
        "    \n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        x               = X_train,\n",
        "        y               = y_train,\n",
        "        batch_size      = batch_size,\n",
        "        epochs          = epochs,\n",
        "        verbose         = 0,\n",
        "        callbacks       = [cb],\n",
        "        validation_data = (X_val, y_val)\n",
        "    )\n",
        "\n",
        "    num_epochs = len(history.history['loss'])\n",
        "\n",
        "    ## Evaluate\n",
        "    # Accuracy\n",
        "    _, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # F1\n",
        "    if model_name == modelname_lstm_MtoM:\n",
        "        y_pred = model.predict(X_test, batch_size=batch_size)\n",
        "        y_pred_last = np.asarray([[i[-1]] for i in y_pred]).reshape(-1, y_pred.shape[-1])\n",
        "        y_pred_last_classes = y_pred_last.argmax(axis=-1)\n",
        "        f1 = f1_score(y_test_classes_lstm_MtoM, y_pred_last_classes, average='weighted')\n",
        "    else:\n",
        "        y_pred = model.predict(X_test)\n",
        "        f1 = f1_score(y_test.argmax(axis=-1), y_pred.argmax(axis=-1), average='weighted')\n",
        "\n",
        "    return accuracy, f1, num_epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ0b9G-Mgbxi"
      },
      "source": [
        "# Repeat experiment\n",
        "def run_experiment(model_name, X_train, X_val, X_test, y_train, y_val, y_test, repeats=10):\n",
        "    print(f'Model: {model_name}')\n",
        "\n",
        "    scores_acc = []\n",
        "    scores_f1 = []\n",
        "    scores_epoch = []\n",
        "    for r in range(repeats):\n",
        "        acc, f1, epoch = evaluate_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "        print(f'[#{r+1:>2d}] Accuracy: {acc:.4f}, F1 score(weighted): {f1:.4f}, epoch: {epoch}')\n",
        "        scores_acc.append(acc)\n",
        "        scores_f1.append(f1)\n",
        "        scores_epoch.append(epoch)\n",
        "    \n",
        "    # Summarise mean and standard deviation\n",
        "    print(f'Accuracy: {mean(scores_acc):.4f} (+/- {std(scores_acc):.4f})')\n",
        "    print(f'F1 score(weighted): {mean(scores_f1):.4f} (+/- {std(scores_f1):.4f})')\n",
        "    print(f'epoch: {mean(scores_epoch):.1f} (+/- {std(scores_epoch):.4f})')\n",
        "\n",
        "\t# Boxplot of scores\n",
        "    metrics_list = ['Accuracy', 'F1 score']\n",
        "    all_scores = []\n",
        "    all_scores.append(scores_acc)\n",
        "    all_scores.append(scores_f1)\n",
        "    plt.boxplot(all_scores, labels=metrics_list)\n",
        "\n",
        "    if flag_savefig:\n",
        "        plt.savefig(\"boxplot_\" + model_name + \".png\")\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vf8LExnjGUe"
      },
      "source": [
        "# Plot a histogram of each variable in the dataset\n",
        "def plot_variable_distributions(X, start=0, end=None, xlim=None):\n",
        "    if end is None:\n",
        "        end = X.shape[1]-1\n",
        "\n",
        "    print(X.shape)\n",
        "    num_features = end - start +1\n",
        "    print(f'# of plots: {num_features} ({start} - {end})')\n",
        "\n",
        "    plt.figure(figsize=(5, 2*num_features), tight_layout=True)\n",
        "    xaxis = None\n",
        "    for i, f in enumerate(range(start, end+1)):\n",
        "        if xlim is None:\n",
        "            ax = plt.subplot(num_features, 1, i+1, title='Feature: ' + str(f+1))\n",
        "        else:\n",
        "            ax = plt.subplot(num_features, 1, i+1, sharex=xaxis, title='Feature: ' + str(f+1))\n",
        "            ax.set_xlim(xlim)\n",
        "        if i == 0:\n",
        "            xaxis = ax\n",
        "        plt.hist(X[:, f], bins=100)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NxZ4CUd_SLc"
      },
      "source": [
        "# Plot graphs for loss and accuracy\n",
        "def plot_acc_graph(history):\n",
        "\n",
        "    # Set figure size\n",
        "    fig = plt.figure(figsize=(15, 6))\n",
        "    plt.subplots_adjust(wspace=0.2)\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['loss'],\n",
        "            label='Train',\n",
        "            color='black')\n",
        "\n",
        "    plt.plot(history.history['val_loss'],\n",
        "            label='Val',\n",
        "            color='red')\n",
        "\n",
        "    #plt.ylim(0, 1)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['accuracy'],\n",
        "            label='Train',\n",
        "            color='black')\n",
        "\n",
        "    plt.plot(history.history['val_accuracy'],\n",
        "            label='Val',\n",
        "            color='red')\n",
        "\n",
        "    plt.ylim(0, 1)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    if flag_savefig:\n",
        "    \tplt.savefig(\"acc_graph_\" + history.model.name + \".png\")\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbALamaCiaA1"
      },
      "source": [
        "# Print execution time\n",
        "def print_execution_time(time_start):\n",
        "    time_elapsed = time.perf_counter() - time_start\n",
        "    min, sec = divmod(time_elapsed, 60)\n",
        "    hour, min = divmod(min, 60)\n",
        "\n",
        "    print(f\"Execution time: {hour:.0f} hour {min:.0f} min {sec:.0f} sec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo2_WEpT_qQ_"
      },
      "source": [
        "# 3.Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PK1efK55oYo"
      },
      "source": [
        "# For CSF3 (UoM) setting\n",
        "import platform\n",
        "system_name = platform.system()\n",
        "print('system_name: ' + system_name)\n",
        "if system_name == \"Linux\":\n",
        "    flag_summary    = False\n",
        "    flag_cm_norm    = False\n",
        "    flag_plot_model = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYkrNawEhkWr"
      },
      "source": [
        "## Read files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEhYkdlFeb2W"
      },
      "source": [
        "if not 'X_train' in locals():\n",
        "    # Load data\n",
        "    X_train, y_train, X_test, y_test = load_dataset()\n",
        "\n",
        "    # Split into train and val (No shuffle)\n",
        "    X_train, X_val, y_train, y_val = \\\n",
        "        train_test_split(X_train, y_train,\n",
        "        train_size   = ratio_train,\n",
        "        random_state = seed,\n",
        "        shuffle      = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByRz5SAuLtYZ"
      },
      "source": [
        "# For evaluation\n",
        "y_test_classes = y_test.argmax(axis=-1)\n",
        "\n",
        "num_timesteps = X_train.shape[1]\n",
        "num_features = X_train.shape[2]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "cnn_lstm_length = int(num_timesteps / cnn_lstm_steps)\n",
        "convlstm_length = int(num_timesteps / convlstm_steps)\n",
        "\n",
        "# For confusion_matrix\n",
        "labels = np.arange(0, num_classes)\n",
        "\n",
        "# Input shape of NNs\n",
        "cnn_1d_input_shape = (num_timesteps, num_features)\n",
        "lstm_input_shape = (num_timesteps, num_features)\n",
        "cnn1d_lstm_input_shape = (None, cnn_lstm_length, num_features)\n",
        "convlstm_input_shape = (convlstm_steps, 1, convlstm_length, num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98bwkTn26Zz_"
      },
      "source": [
        "## (Distributions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVf0EuOQ6Ujb"
      },
      "source": [
        "if flag_data_dist:\n",
        "    # Remove overlap\n",
        "    cut = int(X_train.shape[1] / 2)\n",
        "    X_train_long = X_train[:, -cut:, :]\n",
        "\n",
        "    # Flatten windows\n",
        "    X_train_long = X_train_long.reshape((X_train_long.shape[0] * X_train_long.shape[1], X_train_long.shape[2]))\n",
        "\n",
        "    plot_variable_distributions(X_train_long, start=0, end=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJCpre3SCZJz"
      },
      "source": [
        "## Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dBhtR30CzES"
      },
      "source": [
        "if flag_scaling == \"Norm\":\n",
        "    scaler = MinMaxScaler()\n",
        "elif flag_scaling == \"Std\":\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "# Remove overlap\n",
        "cut = int(X_train.shape[1] / 2)\n",
        "X_train_long = X_train[:, -cut:, :]\n",
        "\n",
        "# Flatten windows\n",
        "X_train_long = X_train_long.reshape((X_train_long.shape[0] * X_train_long.shape[1], X_train_long.shape[2]))\n",
        "\n",
        "# Flatten train, val and test\n",
        "X_train_flat = X_train.reshape((X_train.shape[0] * X_train.shape[1], X_train.shape[2]))\n",
        "X_val_flat = X_val.reshape((X_val.shape[0] * X_val.shape[1], X_val.shape[2]))\n",
        "X_test_flat = X_test.reshape((X_test.shape[0] * X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "# Fit on training data\n",
        "scaler.fit(X_train_long)\n",
        "\n",
        "# Apply to train, val and test\n",
        "X_train_flat = scaler.transform(X_train_flat)\n",
        "X_val_flat = scaler.transform(X_val_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape\n",
        "X_train = X_train_flat.reshape((X_train.shape))\n",
        "X_val = X_val_flat.reshape((X_val.shape))\n",
        "X_test = X_test_flat.reshape((X_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpJ1Guhw6o5m"
      },
      "source": [
        "## (Distributions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cqFo-x76qZ-"
      },
      "source": [
        "if flag_data_dist:\n",
        "    # Remove overlap\n",
        "    cut = int(X_train.shape[1] / 2)\n",
        "    X_train_long = X_train[:, -cut:, :]\n",
        "\n",
        "    # Flatten windows\n",
        "    X_train_long = X_train_long.reshape((X_train_long.shape[0] * X_train_long.shape[1], X_train_long.shape[2]))\n",
        "\n",
        "    plot_variable_distributions(X_train_long, start=0, end=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SkfXm4eYEXG"
      },
      "source": [
        "## [Summary]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3wLGu7vQiEd"
      },
      "source": [
        "if flag_summary:\n",
        "    # The number of samples (train, val, test)\n",
        "    num_samples = len(X_train) + len(X_val) + len(X_test)\n",
        "    num_train = X_train.shape[0]\n",
        "    num_val = X_val.shape[0]\n",
        "    num_test = X_test.shape[0]\n",
        "\n",
        "    num_classes_train = y_train.shape[-1]\n",
        "    num_classes_val = y_val.shape[-1]\n",
        "    num_classes_test = y_test.shape[-1]\n",
        "\n",
        "    y_counts = pd.concat([np.flip(pd.DataFrame(y_train).value_counts(sort=False)),\n",
        "                        np.flip(pd.DataFrame(y_val).value_counts(sort=False)),\n",
        "                        np.flip(pd.DataFrame(y_test).value_counts(sort=False))],\n",
        "                        axis=1)\n",
        "\n",
        "    y_counts = y_counts.style.hide_index().highlight_null('red').set_precision(0)\n",
        "\n",
        "    print('[# of samples]')\n",
        "    print(f'Total: {num_samples:>7,}')\n",
        "    print(f'Train: {num_train:>7,}')\n",
        "    print(f'Val:   {num_val:>7,}')\n",
        "    print(f'Test:  {num_test:>7,}')\n",
        "    print()\n",
        "\n",
        "    print('[# of features]')\n",
        "    print(f'{num_features}')\n",
        "    print()\n",
        "\n",
        "    print('[# of timesteps]')\n",
        "    print(f'{num_timesteps}')\n",
        "    print()\n",
        "\n",
        "    print('[# of classes]')\n",
        "    print(f'Total: {num_classes}')\n",
        "    print(f'Train: {num_classes_train}')\n",
        "    print(f'Val:   {num_classes_val}')\n",
        "    print(f'Test:  {num_classes_test}')\n",
        "    print()\n",
        "\n",
        "    print('[Original data]')\n",
        "    print('Train   Val   Test')\n",
        "    display(y_counts)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywOIh_-nCzjS"
      },
      "source": [
        "# 4.Train & Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIpQ3qHFUCK0"
      },
      "source": [
        "## callbacks\n",
        "cb = []\n",
        "\n",
        "# EarlyStopping\n",
        "if flag_EarlyStopping:\n",
        "    es = EarlyStopping(monitor=flag_es_monitor, patience=es_patience)\n",
        "    cb.append(es)\n",
        "\n",
        "# TensorBoard\n",
        "if flag_TensorBoard:\n",
        "    log_dir = dir_log + '/tb/' + datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
        "    tb = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    cb.append(tb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b51cxnB1P49V"
      },
      "source": [
        "## CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF7MUe6YJDB4"
      },
      "source": [
        "if flag_CNN_1d:\n",
        "    if flag_model_load:\n",
        "        model_cnn_1d = load_model(dir_model + \"/\" + modelname_cnn_1d + \".h5\")\n",
        "    else:\n",
        "        model_cnn_1d = build_model_cnn_1d()\n",
        "    model_cnn_1d.summary()\n",
        "\n",
        "    if flag_plot_model:\n",
        "        plot_model(model_cnn_1d, show_shapes=True, to_file='model_' + model_cnn_1d.name + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wncHGASFJJpP"
      },
      "source": [
        "if flag_CNN_1d:\n",
        "    if not flag_model_load:\n",
        "        time_start = time.perf_counter()\n",
        "\n",
        "        history_cnn_1d = model_cnn_1d.fit(\n",
        "            x               = X_train,\n",
        "            y               = y_train,\n",
        "            batch_size      = batch_size,\n",
        "            epochs          = epochs,\n",
        "            verbose         = 1,\n",
        "            callbacks       = [cb],\n",
        "            validation_data = (X_val, y_val)\n",
        "        )\n",
        "\n",
        "        print_execution_time(time_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI8HzEqJJj8g"
      },
      "source": [
        "if flag_CNN_1d:\n",
        "    if not flag_model_load:\n",
        "        plot_acc_graph(history_cnn_1d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU8QO_166nU9"
      },
      "source": [
        "if flag_CNN_1d:\n",
        "    if flag_model_save:\n",
        "        time_current = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
        "        model_cnn_1d.save(dir_model + '/' + model_cnn_1d.name + '_' + time_current + \".h5\", overwrite=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNzrQwlFJmJ3"
      },
      "source": [
        "if flag_CNN_1d:\n",
        "    y_pred_classes = model_cnn_1d.predict(X_test).argmax(axis=-1)\n",
        "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "    print(f'F1 score(weighted) {f1:.4f}\\n')\n",
        "    print(classification_report(y_test_classes, y_pred_classes, target_names=labels_activity))\n",
        "\n",
        "    if flag_cm_norm:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels, normalize='true')\n",
        "        cm = cm * 100\n",
        "    else:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels)\n",
        "\n",
        "    df_cm = pd.DataFrame(cm, index=labels_activity, columns=labels_activity)\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    sns.heatmap(df_cm, square=True, annot=True, cbar=False, fmt='.0f', cmap='Greens')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    if flag_savefig:\n",
        "    \tplt.savefig(\"confusion_matrix_\" + model_cnn_1d.name + \".png\")\n",
        "\n",
        "    plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lar3HvcgOY74"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3rv4WYFKdUp"
      },
      "source": [
        "if flag_LSTM_Mto1:\n",
        "    if flag_model_load:\n",
        "        model_lstm_Mto1 = load_model(dir_model + \"/\" + modelname_lstm_Mto1 + \".h5\")\n",
        "    else:\n",
        "        model_lstm_Mto1 = build_model_lstm_Mto1()\n",
        "    model_lstm_Mto1.summary()\n",
        "\n",
        "    if flag_plot_model:\n",
        "        plot_model(model_lstm_Mto1, show_shapes=True, to_file='model_' + model_lstm_Mto1.name + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D7O2TKxKj1X"
      },
      "source": [
        "if flag_LSTM_Mto1:\n",
        "    if not flag_model_load:\n",
        "        time_start = time.perf_counter()\n",
        "\n",
        "        history_lstm_Mto1 = model_lstm_Mto1.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            batch_size      = batch_size,\n",
        "            epochs          = epochs,\n",
        "            verbose         = 1,\n",
        "            callbacks       = [cb],\n",
        "            validation_data = (X_val, y_val)\n",
        "        )\n",
        "\n",
        "        print_execution_time(time_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtkBy54A88Pa"
      },
      "source": [
        "if flag_LSTM_Mto1:\n",
        "    if not flag_model_load:\n",
        "        plot_acc_graph(history_lstm_Mto1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ibjsrBKtKI"
      },
      "source": [
        "if flag_LSTM_Mto1:\n",
        "    if flag_model_save:\n",
        "        time_current = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
        "        model_lstm_Mto1.save(dir_model + '/' + model_lstm_Mto1.name + '_' + time_current + \".h5\", overwrite=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1ET3iF3KwiQ"
      },
      "source": [
        "if flag_LSTM_Mto1:\n",
        "    y_pred_classes = model_lstm_Mto1.predict(X_test).argmax(axis=-1)\n",
        "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "    print(f'F1 score(weighted) {f1:.4f}\\n')\n",
        "    print(classification_report(y_test_classes, y_pred_classes, target_names=labels_activity))\n",
        "\n",
        "    if flag_cm_norm:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels, normalize='true')\n",
        "        cm = cm * 100\n",
        "    else:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels)\n",
        "\n",
        "    df_cm = pd.DataFrame(cm, index=labels_activity, columns=labels_activity)\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    sns.heatmap(df_cm, square=True, annot=True, cbar=False, fmt='.0f', cmap='Greens')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    if flag_savefig:\n",
        "    \tplt.savefig(\"confusion_matrix_\" + model_lstm_Mto1.name + \".png\")\n",
        "\n",
        "    plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0nQ_CJvVUoU"
      },
      "source": [
        "## CNN-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sm8vFLjEX-g"
      },
      "source": [
        "# Reshape data into 4D for CNN1D-LSTM\n",
        "X_train_cnn1d_lstm = X_train.reshape((X_train.shape[0], cnn_lstm_steps, cnn_lstm_length, X_train.shape[-1]))\n",
        "X_val_cnn1d_lstm = X_val.reshape((X_val.shape[0], cnn_lstm_steps, cnn_lstm_length, X_val.shape[-1]))\n",
        "X_test_cnn1d_lstm = X_test.reshape((X_test.shape[0], cnn_lstm_steps, cnn_lstm_length, X_test.shape[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krVJWV54VWW-"
      },
      "source": [
        "if flag_CNN1D_LSTM:\n",
        "    if flag_model_load:\n",
        "        model_cnn1d_lstm = load_model(dir_model + \"/\" + modelname_cnn1d_lstm + \".h5\")\n",
        "    else:\n",
        "        model_cnn1d_lstm = build_model_cnn1d_lstm()\n",
        "    model_cnn1d_lstm.summary()\n",
        "\n",
        "    if flag_plot_model:\n",
        "        plot_model(model_cnn1d_lstm, show_shapes=True, to_file='model_' + model_cnn1d_lstm.name + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN_0aOG8YoYj"
      },
      "source": [
        "if flag_CNN1D_LSTM:\n",
        "    if not flag_model_load:\n",
        "        time_start = time.perf_counter()\n",
        "\n",
        "        history_cnn1d_lstm = model_cnn1d_lstm.fit(\n",
        "            X_train_cnn1d_lstm,\n",
        "            y_train,\n",
        "            batch_size      = batch_size,\n",
        "            epochs          = epochs,\n",
        "            verbose         = 1,\n",
        "            callbacks       = [cb],\n",
        "            validation_data = (X_val_cnn1d_lstm, y_val)\n",
        "        )\n",
        "\n",
        "        print_execution_time(time_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruqui2vmRUct"
      },
      "source": [
        "if flag_CNN1D_LSTM:\n",
        "    if not flag_model_load:\n",
        "        plot_acc_graph(history_cnn1d_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkbgQ7zo-LVq"
      },
      "source": [
        "if flag_CNN1D_LSTM:\n",
        "    if flag_model_save:\n",
        "        time_current = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
        "        model_cnn1d_lstm.save(dir_model + '/' + model_cnn1d_lstm.name + '_' + time_current + \".h5\", overwrite=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRagkHvMRagu"
      },
      "source": [
        "if flag_CNN1D_LSTM:\n",
        "    y_pred_classes = model_cnn1d_lstm.predict(X_test_cnn1d_lstm).argmax(axis=-1)\n",
        "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "    print(f'F1 score(weighted) {f1:.4f}\\n')\n",
        "    print(classification_report(y_test_classes, y_pred_classes, target_names=labels_activity))\n",
        "\n",
        "    if flag_cm_norm:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels, normalize='true')\n",
        "        cm = cm * 100\n",
        "    else:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels)\n",
        "\n",
        "    df_cm = pd.DataFrame(cm, index=labels_activity, columns=labels_activity)\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    sns.heatmap(df_cm, square=True, annot=True, cbar=False, fmt='.0f', cmap='Greens')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    if flag_savefig:\n",
        "    \tplt.savefig(\"confusion_matrix_\" + model_cnn1d_lstm.name + \".png\")\n",
        "\n",
        "    plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CcWqW3NUBR0"
      },
      "source": [
        "## ConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny9_LxRbUDCc"
      },
      "source": [
        "# Reshape data into 5D for ConvLSTM\n",
        "X_train_convlstm = X_train.reshape((X_train.shape[0], convlstm_steps, 1, convlstm_length, X_train.shape[-1]))\n",
        "X_val_convlstm = X_val.reshape((X_val.shape[0], convlstm_steps, 1, convlstm_length, X_val.shape[-1]))\n",
        "X_test_convlstm = X_test.reshape((X_test.shape[0], convlstm_steps, 1, convlstm_length, X_test.shape[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_guH2InUrBa"
      },
      "source": [
        "if flag_ConvLSTM:\n",
        "    if flag_model_load:\n",
        "        model_convlstm = load_model(dir_model + \"/\" + modelname_convlstm + \".h5\")\n",
        "    else:\n",
        "        model_convlstm = build_model_convlstm()\n",
        "    model_convlstm.summary()\n",
        "\n",
        "    if flag_plot_model:\n",
        "        plot_model(model_convlstm, show_shapes=True, to_file='model_' + model_convlstm.name + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ibm6HvQWrlB"
      },
      "source": [
        "if flag_ConvLSTM:\n",
        "    if not flag_model_load:\n",
        "        time_start = time.perf_counter()\n",
        "\n",
        "        history_convlstm = model_convlstm.fit(\n",
        "            X_train_convlstm,\n",
        "            y_train,\n",
        "            batch_size      = batch_size,\n",
        "            epochs          = epochs,\n",
        "            verbose         = 1,\n",
        "            callbacks       = [cb],\n",
        "            validation_data = (X_val_convlstm, y_val)\n",
        "        )\n",
        "\n",
        "        print_execution_time(time_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxfj1nTLXqzC"
      },
      "source": [
        "if flag_ConvLSTM:\n",
        "    if not flag_model_load:\n",
        "        plot_acc_graph(history_convlstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7d0xMcB-b9h"
      },
      "source": [
        "if flag_ConvLSTM:\n",
        "    if flag_model_save:\n",
        "        time_current = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
        "        model_convlstm.save(dir_model + '/' + model_convlstm.name + '_' + time_current + \".h5\", overwrite=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuUpw2EUXzc7"
      },
      "source": [
        "if flag_ConvLSTM:\n",
        "    y_pred_classes = model_convlstm.predict(X_test_convlstm).argmax(axis=-1)\n",
        "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "    print(f'F1 score(weighted) {f1:.4f}\\n')\n",
        "    print(classification_report(y_test_classes, y_pred_classes, target_names=labels_activity))\n",
        "\n",
        "    if flag_cm_norm:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels, normalize='true')\n",
        "        cm = cm * 100\n",
        "    else:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels)\n",
        "\n",
        "    df_cm = pd.DataFrame(cm, index=labels_activity, columns=labels_activity)\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    sns.heatmap(df_cm, square=True, annot=True, cbar=False, fmt='.0f', cmap='Greens')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    if flag_savefig:\n",
        "    \tplt.savefig(\"confusion_matrix_\" + model_convlstm.name + \".png\")\n",
        "\n",
        "    plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz1ssCrTRmAc"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB4jdpkyqnfw"
      },
      "source": [
        "if flag_Ensemble:\n",
        "    # build sub-models\n",
        "    sub_models = list()\n",
        "    X_train_ensemble = list()\n",
        "    X_val_ensemble = list()\n",
        "    X_test_ensemble = list()\n",
        "\n",
        "    if flag_CNN_1d:\n",
        "        sub_models.append(model_cnn_1d)\n",
        "        X_train_ensemble.append(X_train)\n",
        "        X_val_ensemble.append(X_val)\n",
        "        X_test_ensemble.append(X_test)\n",
        "    if flag_LSTM_Mto1:\n",
        "        sub_models.append(model_lstm_Mto1)\n",
        "        X_train_ensemble.append(X_train)\n",
        "        X_val_ensemble.append(X_val)\n",
        "        X_test_ensemble.append(X_test)\n",
        "    if flag_CNN1D_LSTM:\n",
        "        sub_models.append(model_cnn1d_lstm)\n",
        "        X_train_ensemble.append(X_train_cnn1d_lstm)\n",
        "        X_val_ensemble.append(X_val_cnn1d_lstm)\n",
        "        X_test_ensemble.append(X_test_cnn1d_lstm)\n",
        "    if flag_ConvLSTM:\n",
        "        sub_models.append(model_convlstm)\n",
        "        X_train_ensemble.append(X_train_convlstm)\n",
        "        X_val_ensemble.append(X_val_convlstm)\n",
        "        X_test_ensemble.append(X_test_convlstm)\n",
        "\n",
        "    # freeze parameters for sub-models\n",
        "    for i in range(len(sub_models)):\n",
        "        for layer in sub_models[i].layers:\n",
        "            layer.trainable = False\n",
        "            layer._name = 'ensemble_' + sub_models[i].name + '_' + layer.name\n",
        "\n",
        "    inputs = [model.input for model in sub_models]\n",
        "    outputs = [model.output for model in sub_models]\n",
        "\n",
        "    model_ensemble = build_model_ensemble(inputs, outputs)\n",
        "    model_ensemble.summary()\n",
        "\n",
        "    if flag_plot_model:\n",
        "        plot_model(model_ensemble, show_shapes=True, to_file='model_' + model_ensemble.name + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPtmF3VK43hv"
      },
      "source": [
        "if flag_Ensemble:\n",
        "    history_ensemble    = model_ensemble.fit(\n",
        "        x               = X_train_ensemble,\n",
        "        y               = y_train,\n",
        "        batch_size      = batch_size,\n",
        "        epochs          = epochs,\n",
        "        verbose         = 1,\n",
        "        callbacks       = [cb],\n",
        "        validation_data = (X_val_ensemble, y_val)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOVhjDErI8Zp"
      },
      "source": [
        "if flag_Ensemble:\n",
        "    plot_acc_graph(history_ensemble)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh4FArLutRVC"
      },
      "source": [
        "if flag_Ensemble:\n",
        "    y_pred_classes = model_ensemble.predict(X_test_ensemble).argmax(axis=-1)\n",
        "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "    print(f'F1 score(weighted) {f1:.4f}\\n')\n",
        "    print(classification_report(y_test_classes, y_pred_classes, target_names=labels_activity))\n",
        "\n",
        "    if flag_cm_norm:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels, normalize='true')\n",
        "        cm = cm * 100\n",
        "    else:\n",
        "        cm = confusion_matrix(y_test_classes, y_pred_classes, labels=labels)\n",
        "\n",
        "    df_cm = pd.DataFrame(cm, index=labels_activity, columns=labels_activity)\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    sns.heatmap(df_cm, square=True, annot=True, cbar=False, fmt='.0f', cmap='Greens')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    if flag_savefig:\n",
        "        plt.savefig(\"confusion_matrix_\" + model_ensemble.name + \".png\")\n",
        "\n",
        "    plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnZhVUx0nM0g"
      },
      "source": [
        "# 5.Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXh1grdwmJ--"
      },
      "source": [
        "if flag_experiment:\n",
        "    time_start = time.perf_counter()\n",
        "\n",
        "    print(f'repeats: {repeats}, epochs: {epochs}, batch_size: {batch_size}')\n",
        "    if flag_EarlyStopping:\n",
        "        print(f' EarlyStopping is set (patience: {es_patience})\\n')\n",
        "    else:\n",
        "        print(f' no EarlyStopping\\n')\n",
        "\n",
        "    ## CNN 1D\n",
        "    run_experiment(modelname_cnn_1d,\n",
        "                   X_train, X_val, X_test,\n",
        "                   y_train, y_val, y_test,\n",
        "                   repeats=repeats)\n",
        "\n",
        "    ## LSTM Mto1 (stateless)\n",
        "    run_experiment(modelname_lstm_Mto1,\n",
        "                   X_train, X_val, X_test,\n",
        "                   y_train, y_val, y_test,\n",
        "                   repeats=repeats)\n",
        "\n",
        "    ## CNN1D-LSTM\n",
        "    run_experiment(modelname_cnn1d_lstm,\n",
        "                   X_train_cnn1d_lstm, X_val_cnn1d_lstm, X_test_cnn1d_lstm,\n",
        "                   y_train, y_val, y_test,\n",
        "                   repeats=repeats)\n",
        "\n",
        "    ## ConvLSTM\n",
        "    run_experiment(modelname_convlstm,\n",
        "                   X_train_convlstm, X_val_convlstm, X_test_convlstm,\n",
        "                   y_train, y_val, y_test,\n",
        "                   repeats=repeats)\n",
        "    \n",
        "    print_execution_time(time_start)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}